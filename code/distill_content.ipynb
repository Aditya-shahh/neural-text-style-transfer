{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aind2/anaconda3/envs/aind2/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import pickle as pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from utils import *\n",
    "from nn import *\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1004399 tweets from 4391 unique users.\n",
      "Loading Twitter dataset took 3 seconds.\n",
      "Number of Tweets: 97728\n",
      "Only keeping characters that appear at least 100 times in the corpus\n",
      "Character set consists of 246 characters\n",
      "Building X...\n",
      "Building Y...\n",
      "Splitting Data...\n",
      "79159 train char sequences\n",
      "9773 test char sequences\n",
      "8796 validation char sequences\n"
     ]
    }
   ],
   "source": [
    "# import all the data\n",
    "data = load_10_people()\n",
    "X_train_ohe = data['X_train'].astype(np.float64)\n",
    "X_train_nums = X_train_ohe.argmax(-1)\n",
    "Y_train = data['Y_train'].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the encoder RNN with one GRU cell\n",
    "vocab_size = 246\n",
    "embedding_size = 100\n",
    "max_seq_length = 140\n",
    "n_layers = 1\n",
    "batch_size = 50\n",
    "dropout_rate = 0.5\n",
    "dim_y = 10\n",
    "dim_h = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_cell(dim, n_layers, dropout):\n",
    "    cell = tf.nn.rnn_cell.GRUCell(dim)\n",
    "    cell = tf.nn.rnn_cell.DropoutWrapper(cell,\n",
    "        input_keep_prob=dropout)\n",
    "    if n_layers > 1:\n",
    "        cell = tf.nn.rnn_cell.MultiRNNCell([cell] * n_layers)\n",
    "    return cell\n",
    "\n",
    "def linear(inp, dim_out, scope, reuse=False):\n",
    "    dim_in = inp.get_shape().as_list()[-1]\n",
    "    with tf.variable_scope(scope) as vs:\n",
    "        if reuse:\n",
    "            vs.reuse_variables()\n",
    "\n",
    "        W = tf.get_variable('W', [dim_in, dim_out])\n",
    "        b = tf.get_variable('b', [dim_out])\n",
    "    return tf.matmul(inp, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "encoder_inputs = tf.placeholder(shape = [batch_size, max_seq_length], name = \"input_sentences\", dtype=tf.int32)\n",
    "targets = tf.placeholder(shape = [batch_size, max_seq_length, vocab_size], name = \"target_sentences\", dtype=tf.int32)\n",
    "labels = tf.placeholder(shape = [batch_size], name = 'labels', dtype=tf.int32)\n",
    "\n",
    "labels = tf.reshape(labels, [-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape:0' shape=(50, 1) dtype=int32>"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_inputs\n",
    "targets\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'embedding_matrix:0' shape=(246, 100) dtype=float32_ref>"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embedding matrices\n",
    "# TensorShape([Dimension(246), Dimension(100)])\n",
    "embedding_encoder = tf.get_variable(\"embedding_matrix\", [vocab_size, embedding_size])\n",
    "embedding_decoder = tf.get_variable(\"output_embedding_matrix\", [vocab_size, embedding_size])\n",
    "embedding_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'encoder_embeddings:0' shape=(50, 140, 100) dtype=float32>"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract Embeddings\n",
    "#TensorShape([Dimension(140), Dimension(50), Dimension(100)])\n",
    "encoder_emb_inp = tf.nn.embedding_lookup(embedding_encoder, encoder_inputs, name = \"encoder_embeddings\")\n",
    "encoder_emb_out = tf.nn.embedding_lookup(embedding_decoder, encoder_inputs, name = \"decoder_embeddings\")\n",
    "encoder_emb_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder Net\n",
    "cell_e = create_cell(dim_h, n_layers, dropout_rate)\n",
    "_, z = tf.nn.dynamic_rnn(cell_e, encoder_emb_inp, dtype = tf.float32, scope='encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder Net\n",
    "cell_g = create_cell(dim_h, n_layers, dropout_rate)\n",
    "g_outputs, _ = tf.nn.dynamic_rnn(cell_g, encoder_emb_out,\n",
    "            initial_state = z, scope='generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add:0' shape=(7000, 246) dtype=float32>"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take the output and predict words\n",
    "with tf.variable_scope('projection'):\n",
    "            proj_W = tf.get_variable('W', [dim_h, vocab_size])\n",
    "            proj_b = tf.get_variable('b', [vocab_size])\n",
    "            \n",
    "g_outputs = tf.nn.dropout(g_outputs, dropout_rate)\n",
    "g_outputs = tf.reshape(g_outputs, [-1, dim_h])\n",
    "g_logits = tf.matmul(g_outputs, proj_W) + proj_b\n",
    "g_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'truediv_17:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reconstruction error\n",
    "loss_g = tf.nn.softmax_cross_entropy_with_logits(\n",
    "            labels=tf.reshape(targets, [-1, vocab_size]), logits=g_logits)\n",
    "loss_g = tf.reduce_sum(loss_g) / tf.to_float(batch_size)\n",
    "\n",
    "preds = tf.argmax(tf.nn.softmax(g_logits), -1)\n",
    "goalz = tf.cast(tf.reshape(encoder_inputs, [-1]), tf.int64)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(preds, goalz), tf.float32))\n",
    "loss_g = tf.reduce_sum(loss_g) / tf.to_float(batch_size)\n",
    "loss_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run([tf.global_variables_initializer()])\n",
    "for i in tqdm(range(0, len(X_train-50))):\n",
    "    _, l, a = sess.run([optimizer, loss_g, accuracy], feed_dict={encoder_inputs: X_train_nums[i:i+50], \n",
    "                                                   targets: X_train_ohe[i:i+50],\n",
    "                                                   labels: np.argmax(Y_train[i:i+50], 1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
