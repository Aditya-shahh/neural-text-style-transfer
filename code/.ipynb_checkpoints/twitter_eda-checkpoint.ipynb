{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "twitter_data_dir = \"../data/authorship_corpora/influencer_tweets.json\"\n",
    "json_data=open(twitter_data_dir).read()\n",
    "twitter_data = json.loads(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How many Tweets\n",
    "print(\"Number of Tweets: {}\".format(len(twitter_data)))\n",
    "print()\n",
    "\n",
    "# How many Users\n",
    "count_ = {}\n",
    "\n",
    "for item in twitter_data:\n",
    "    user = item['user']\n",
    "    if user not in count_.keys():\n",
    "        count_[user] = 1\n",
    "    else:\n",
    "        count_[user] += 1\n",
    "    \n",
    "print(\"Number of Influencers: {}\".format(len(count_.keys())))\n",
    "print()\n",
    "\n",
    "print(\"Top Influencers\")\n",
    "print(\"---------------\")\n",
    "print()\n",
    "# Top influencers\n",
    "for influencer, count in sorted(count_.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(\"Influencer Twitter ID: {}\".format(influencer))\n",
    "    print(\"# of tweets: {}\".format(count))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Distribution of the length of the tweets\n",
    "char_len = []\n",
    "word_len = []\n",
    "tknzr = TweetTokenizer()\n",
    "\n",
    "# takes 5 mins to run\n",
    "for tweet in tqdm(twitter_data):\n",
    "    words = tknzr.tokenize(tweet['text'].lower())\n",
    "    words = [''.join(c for c in s if c not in list(string.punctuation)) for s in words]\n",
    "    while '' in tokenized_story:\n",
    "        tokenized_story.remove('')\n",
    "    char_len.append(len(tweet['text'].lower()))\n",
    "    word_len.append(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_len = np.array(char_len)\n",
    "word_len = np.array(word_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Character Length\n",
    "print(\"Mean: {}\".format(np.mean(char_len)))\n",
    "print(\"SD: {}\".format(np.std(char_len)))\n",
    "print(\"Min: {}\".format(np.min(char_len)))\n",
    "print(\"25%: {}\".format(np.percentile(char_len, 25)))\n",
    "print(\"50%: {}\".format(np.percentile(char_len, 50)))\n",
    "print(\"75%: {}\".format(np.percentile(char_len, 75)))\n",
    "print(\"Max: {}\".format(np.max(char_len)))\n",
    "plt.hist(char_len, bins = np.arange(min(char_len), max(char_len), 20))\n",
    "print(\"Prop. below 140 chars: {}\".format(np.mean(char_len<=140)))\n",
    "plt.title(\"Character Length in dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be about 3% of the tweets that exceed those 140 character limit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(char_len[char_len<=140], bins = np.arange(0, 141, 10))\n",
    "plt.title(\"Character Level in Tweets < 140 chars\")\n",
    "tix = plt.xticks(np.arange(0, 141, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Word Length\n",
    "print(\"Mean: {}\".format(np.mean(word_len)))\n",
    "print(\"SD: {}\".format(np.std(word_len)))\n",
    "print(\"Min: {}\".format(np.min(word_len)))\n",
    "print(\"25%: {}\".format(np.percentile(word_len, 25)))\n",
    "print(\"50%: {}\".format(np.percentile(word_len, 50)))\n",
    "print(\"75%: {}\".format(np.percentile(word_len, 75)))\n",
    "print(\"Max: {}\".format(np.max(word_len)))\n",
    "plt.hist(char_len, bins = np.arange(min(word_len), max(word_len), 5))\n",
    "plt.title(\"Character Length in dataset\")\n",
    "tix = plt.xticks(np.arange(min(word_len), max(word_len), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How many tweets contain a link or other username?\n",
    "text = []\n",
    "author = []\n",
    "\n",
    "twitter_username_regex = '@([A-Za-z0-9_]+)'\n",
    "link_regex = '(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?'\n",
    "\n",
    "\n",
    "for t in tqdm(twitter_data):\n",
    "    text.append(t['text'])\n",
    "    author.append(t['user'])\n",
    "    \n",
    "data = pd.DataFrame.from_dict({\"author\":author, \"text\":text})\n",
    "\n",
    "is_response = lambda x: int(re.search(twitter_username_regex, x) == None)\n",
    "has_link = lambda x: int(re.search(link_regex, x) == None)\n",
    "data['char_len'] = data['text'].str.len()\n",
    "data['is_response'] = data['text'].apply(is_response) \n",
    "data['has_link'] = data['text'].apply(has_link) \n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Proportion of Tweets that contain a link: {}\".format(np.mean(data['has_link'])))\n",
    "print(\"Proportion of Tweets that are a response: {}\".format(np.mean(data['is_response'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's find all the unique symbols used in the corpus\n",
    "symbols = {}\n",
    "\n",
    "for t in tqdm(data['text']):\n",
    "    for s in t:\n",
    "        if s not in symbols.keys():\n",
    "            symbols[s] = 1\n",
    "        else:\n",
    "            symbols[s] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# all characters\n",
    "print(\"Number of unique characters: {}\".format(len(set(symbols.keys()))))\n",
    "list(set(symbols.keys()))[:10] # emoticons ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# most popular characters\n",
    "plt.figure(figsize=(10, 5))\n",
    "top_100 = sorted(symbols.items(), key = lambda x: x[1], reverse=True)[:100]\n",
    "plt.bar(np.arange(100), width=1, height = [tmp[1] for tmp in top_100])\n",
    "tix = plt.xticks(np.arange(100), [tmp[0] for tmp in top_100], rotation=30)\n",
    "plt.title(\"Most popular characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposed Preprocessing\n",
    "\n",
    "* Keep tweets with a maximum of 140 characters.\n",
    "* We need some minimum text length that we can work with.\n",
    "* What to do with responses/links.\n",
    "* Some care should be taken when making a vocabulary of characters (introduce <ukn> token perhaps?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a character level model to learn character embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
